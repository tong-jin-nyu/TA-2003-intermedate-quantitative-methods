---
title: "APSTA-GE 2003: Intermediate Quantitative Methods"
subtitle: "Lab Section 003, Week 9"
institute: "New York University"
date: "11/03/2020"
output:
  xaringan::moon_reader:
    css: ["styles.css", "styles-font.css"]
    self_contained: TRUE
    seal: TRUE
    lib_dir: libs
    nature:
      ratio: '16:10'
      highlightStyle: github
      highlightLines: TRUE
      countIncrementalSlides: FALSE
---

```{r setup, include=FALSE}
# Author: Tong Jin
# Date created: 11/03/2020
# Date modified: 11/03/2020

knitr::opts_chunk$set(
  echo = TRUE, 
  message=FALSE, 
  warning=FALSE, 
  fig.height = 6,
  fig.width = 10
)

# Dependencies
library(plotly)
library(datarium)
library(dplyr)
library(DT)
library(grid)
library(gridExtra)
```

## Reminders
  
- **Assignment 5**

  - Due: **11/06/2020 11:55pm (EST)**
  
- Office hours

  - Monday 9:00 - 10:00am (EST)
  - Wednesday 12:30 - 1:30pm (EST)
  - Additional time slots available
    - Sign-up sheet [HERE](https://docs.google.com/spreadsheets/d/1YY38yj8uCNIm1E7jaI9TJC494Pye2-Blq9eSK_eh6tI/edit?usp=sharing)
  
- Office hour Zoom link [HERE](https://nyu.zoom.us/j/9985119253)
  
- Office hour notes
  - Available on NYU Classes

---

## Today's Topics

- Regression Analysis using a Simulated Dataset

---

## Introduction

In this lab, we will conduct a study on test preparation courses. We will use regression analysis to examine the effects of test preparation courses to student's test performance. Specifically, we will try to answer the following research questions:

1. How effective are test preparation courses? 

2. Are there any other major factors that contribute to student's test scores?

3. What would be the best way to improve student scores on each test?

## Design

We will use a simulated dataset which includes test scores from three exams and a variety of demographic factors.

First, we will conduct an **Exploratory Data Analysis (EDA)** to describe our data.

Then, we will build a linear regression model to examine the influence of each variable on student's test scores.

Finally, we will use our model make predictions.

---

## Dataset

The dataset includes exam scores for students at a public school. (Source: [Exam Scores](http://roycekimmons.com/tools/generated_data/exams))

It is a simulated dataset created by a data generating process. 

After loading the dataset to RStudio, we need to first describe the data.

```{r load-data}
dat <- read.csv("exams.csv", header = TRUE) #<<
dim(dat)
```

Number of observations: 1,000

Number of columns: 8

Column Names: 

```{r dis-column-names}
colnames(dat)
```

---

## Overview

```{r overview}
head(dat)
```

---

## Describe

- Examine if there is any missing value.

```{r describe-0}
table(is.na(dat))
```

- Get a snapshot of the dataset

```{r describe}
str(dat)
```

--

It seems that we need to simplify column names and update the coding format on values.

---

## Data Processing

It is best practice to process the data before applying analysis techniques. 

1. Rename column names in a concise but meaningful way. 

2. For numeric variables, consider rounding up

3. For categorical variables, consider dummy coding before applying the regression model. 

4. For levels in a categorical variable, check if the levels are correct (e.g. Income level from in ascending).

```{r data-processing}
# Rename column names
new_col_names <- c("is_male", "race", "par_educ", "is_freelunch", "is_treat", "math", "reading", "writing") #<<
colnames(dat) <- new_col_names
# Relevel education
dat$par_educ <- factor(dat$par_educ, levels = levels(dat$par_educ)[c(6, 3, 5, 1, 2, 4)]) #<<
```

---

## Descriptive Analysis: Summary

Then, let's take a closer look on our data. 

For numeric variables, use `summary()` to create a table with summary statistics. 

For categorical variables, use `table()` to examine the distribution of unique values.

```{r temp-summary}
# For numeric variables, use summary(); for categorical, use table()
# Check the distribution of student's math score
summary(dat$math)
# Check the distribution of biological sex
table(dat$is_male)
```

---

## Results - Descriptive: Summary

```{r actual-summary}
summary(dat[, 6:8])

for (i in 1:4) {
  print(table(dat[, i]))
}
```

---

## Descriptive Analysis: Visualization

We can also use plots to visualize columns. Let's create a histogram on reading scores.

```{r temp-summary-viz}
hist(dat$reading)
```

---

## Results - Descriptive: Viz

```{r actual-summary-viz}
par(mfrow = c(2, 4))
plot(dat$is_male)
plot(dat$par_educ)
plot(dat$is_freelunch)
plot(dat$is_treat)
plot(dat$race)
hist(dat$math)
hist(dat$reading)
hist(dat$writing)
```

---

## Interpretation and Inference

1. **Check correlation.** Base on precedent studies, `income` and `education` are positively correlated. In this case, `is_freelunch` maybe highly correlated with `par_educ`.

2. **Test difference.** The `sex` column has equal distributions between `male` and `female`. We need to examine if `sex` affects test scores. We can also test on other binary variables, such as`is_freelunch` and `is_treat`. 

3. **Check correlation among test scores.** Are the three test scores correlated? If so, in what direction?

4. **Choose the model.** Which model should we use?

5. **Estimate effects.** Build regression models to estimate effects. 

---

## Our plan

1. **Check correlation.** Create a correlation matrix that includes all variables. 

2. **Test difference.** Conduct separate T-test on binary variables to examine difference.

3. **Choose the model.** Multiple linear regression model. Add interaction effects based on correlation results.

5. **Estimate effects.** Build a multiple linear regression model for each test score. Repeat. 

---

## Get Ready for Analysis

First, we need to convert categorical/factorial variables to dummy. 

```{r dummy-coding}
# Store a copy of the original dataset by duplicating
dat1 <- dat
# Convert categorical factor columns to dummy
dat$is_male <- as.numeric(ifelse(dat$is_male == "male", yes = 1, no = 0))
dat$is_freelunch <- as.numeric(ifelse(dat$is_freelunch == "standard", yes = 0, no = 1))
dat$is_treat <- as.numeric(ifelse(dat$is_treat == "completed", yes = 1, no = 0))
dat$race <- as.numeric(dat$race)
dat$par_educ <- as.numeric(dat$par_educ)
str(dat)
```

---

## Check correlation

Recall: 

$$\text{corr}(X, Y) = \frac{\text{cov}(X, Y)}{\sigma_X \sigma_Y} = \frac{\frac{\sum_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y})}{n}}{\sigma_X \sigma_Y}$$

Let's calculate the correlation between `reading` and `writing`.

```{r corr-manual}
n <- nrow(dat)
avg_reading <- mean(dat$reading)
avg_writing <- mean(dat$writing)
sd_reading <- sd(dat$reading)
sd_writing <- sd(dat$writing)
(sum((dat$reading - avg_reading) * (dat$writing - avg_writing)) / n) / (sd_reading * sd_writing)
```

---

## Results - Check correlation

```{r actual-corr}
cor(dat)
```

---

## Results - Visualize correlation

```{r actual-corr-viz}
library(corrplot)
corrplot(cor(dat), type = "lower") #<<
```

---

## Test difference

We will then use T tests to check if there is any difference between binary categories. 

```{r t-test-male}
t.test(math ~ is_male, data = dat)

t.test(math ~ is_male, data = dat)$p.value
t.test(math ~ is_freelunch, data = dat)$p.value
t.test(math ~ is_treat, data = dat)$p.value
```

---

## Build a baseline model

Build a multiple linear regression model on `math` with additive effects only:

```{r lin-mod-baseline}
lm_BL <- lm(math ~ is_male + is_freelunch + is_treat + factor(race) + factor(par_educ), data = dat)
summary(lm_BL)
```

---

## Check interaction effects

```{r inter-plot}
par(mfrow = c(1, 3))
interaction.plot(x.factor = dat$race, trace.factor = dat$is_male, response = dat$math)
interaction.plot(x.factor = dat$par_educ, trace.factor = dat$is_male, response = dat$math)
interaction.plot(x.factor = dat$par_educ, trace.factor = dat$is_freelunch, response = dat$math)
```

---

## Let's Improve Our Model Together!

---

## Contact

Tong Jin

- Email: tj1061@nyu.edu
- Office Hours
  - Mondays, 9 - 10am (EST)
  - Wednesdays, 12:30 - 1:30pm (EST)

